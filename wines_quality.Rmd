---
title: "wine_quality"
author: "LJSSE"
date: "19/5/2021"
output: html_document
---

### Importing packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(reshape2)
library(mlr3learners)
library(pROC)
library(corrplot)
library(gridExtra)
library(GGally)
library(car)
library(broom)
library(ltm)
library(MASS)
```

################################################################################
## DATA

The dataset **white_wines.csv** stores data about physicochemical properties of many wines which come from the north-west region, named Minho, of Portugal.

Each row refers to a wine and each column contains one of the physicochemical properties with respect to wines. Here we list the properties:

- fixed acidity (FA: g(tartaric acid)/dm^3)
- volatile acidity (VA: g(acetic acid)/dm^3)
- citric acid (CA: g/dm^3)
- residual sugar (RS: g/dm^3)
- chlorides (CH: g(sodium chloride)/dm^3)
- free sulfur dioxide (FSD: mg/dm^3)
- total sulfur dioxide (TSD: mg/dm^3)
- density (DE: g/dm^3)
- pH
- sulphates (SU: g(potassium sulphate)/dm^3)
- alcohol (AL: %vol)
- quality (from 0 to 10)

Our aim will be to classify white wines according to their quality, labeling them as "low" if their quality score is from 0 to 5, and as "high" if the score is between 6 and 10.


## Loading the dataset

```{r, message=FALSE, warning = FALSE}
wwines <- read.csv("winequality-white.csv", sep=";")
print("White wines")
str(wwines)
```

Now we inspect the variables we have and we transform them if necessary.

## Defining the target: high and low quality

```{r, message=FALSE, warning = FALSE}
wwines$quality <- as.factor(case_when(wwines$quality <= 5 ~ "low",
                                      wwines$quality > 5 ~ "high"))
wwines$quality <- factor(wwines$quality, levels = c("low","high"))
table(wwines$quality)
```


## Data description

### Heatmap
```{r}
#compute on all features (without output variable which is at index 12)
cors <- cor(wwines[-12])
corrplot(cors, type = "upper", 
         tl.col = "black", tl.srt = 45)

```
We have to worry about two correlations: residual.sugar with density and density with alcohol.

### Histograms
```{r}
residual.sugar.plot <- ggplot(wwines, aes(residual.sugar, color = quality))+
  geom_freqpoly(binwidth = 3, size = 1)

alcohol.plot <- ggplot(wwines, aes(alcohol, color = quality))+
  geom_freqpoly(binwidth = 3, size = 1)

density.plot <- ggplot(wwines, aes(density, color = quality))+
  geom_freqpoly(binwidth = 3, size = 1)

grid.arrange(residual.sugar.plot,alcohol.plot,density.plot, ncol=1)

```
We decide to remove density, as this will solve both the correlation issues, and we can see from the histograms below that the distribution of density does not depend on quality, while the shape of the residual.sugar and alcohol curves changes for low and high quality wines.

```{r}
wwines$density <- NULL
```

### Correlation with target variable
```{r, warning=FALSE, message=FALSE}
bicorrs <- sapply(wwines[,-11], function(x) round(biserial.cor(x,wwines$quality),2))
data.frame(bicorrs) %>% arrange(abs(bicorrs))
```
Here the correlations are displayed in ascending absolute value, and we can see that the variable showing the highest correlation with wines' quality is alcohol.
The sign is positive, meaning that as alcohol increases the quality of wine also increases.

### Boxplots
```{r, message=FALSE, warning = FALSE}
summary(wwines)
# melt the dataset
wwines.m <- melt(wwines, id.var = "quality")

# wrapped boxplots
ggplot(data = wwines.m, aes(x=variable, y=value)) +
geom_boxplot(aes(fill=quality)) +
facet_wrap( ~ variable, scales="free")
```


These plots allow us to get a first impression about which variables will be significant for the regression.

We can observe the following:
- The features displaying the highest median difference between high and low quality wines are volatile.acidity, total.sulfur.dioxide, pH, alcohol.
- There are some outlying values. We will deal with them in the section below.


###########################################################################

# LOGISTIC REGRESSION 

## Divide the dataset in training and test

```{r}
set.seed(42)
train_indices<- createDataPartition(wwines$quality,p=0.7,list=FALSE)
```

## Complete model: all variables are included

Estimated coefficients and Odds Ratios.
The baseline for the regression is "low", because positive factor is: "high".

```{r, message=FALSE, warning=FALSE}
lr_fit <- glm(quality ~., data =  wwines[train_indices,],
          family=binomial(link='logit'))

# coefficients
summary(lr_fit)

# odds ratios
exp(cbind(OR = coef(lr_fit), confint(lr_fit)))
```
Here we find these variable which are significant at 99% confidence level: ◊check values
- Intercept 99.97%: this value corresponds to the increase in the odds of having a low quality wine when all the explanatory variables are set at 0.
- volatile.acidity: a unitary increase in volatile acidity will lead to a 99.87% decrease in the odds of having a low quality wine.
- residual.sugar: a unitary increase in volatile acidity will lead to a 7.44% increase in the odds of having a low quality wine.
- free.sulfur.dioxide: a unitary increase in volatile acidity will lead to a 1.36% increase in the odds of having a low quality wine.
- alcohol: a unitary increase in volatile acidity will lead to a 186.5% increase in the odds of having a low quality wine.

We find these variable which are significant at 95% confidence level:
- fixed.acidity: a unitary increase in volatile acidity will lead to a 16.68% decrease in the odds of having a low quality wine.
- sulphates: a unitary increase in volatile acidity will lead to a 283.46% increase in the odds of having a low quality wine.

We find this variable which is significant at 90% confidence level:
- total.sulfur.dioxide: a unitary increase in volatile acidity will lead to a 0.32% decrease in the odds of having a low quality wine.


### Finding the optimal threshold for discriminating high quality wines from low quality wines

```{r}
#here we use mlr3 package
#defining our task: classification on wines with quality as response variable and low quality as baseline
task_train = TaskClassif$new(id = "wines",  wwines[train_indices,], target = "quality", positive = "high")
#defining the learner which will perform the training procedure on our model
learner_train = lrn("classif.log_reg", predict_type = "prob")
#defining how we want to perform cross validation (setting number of folds to 5)
cv5 = rsmp("cv", folds = 5)
#we want to tweak the threshold of our classification: we analyze values from 0.3 to 0.6 with step 0.01
thresholds <- seq(0.5,0.8,0.01)

#collecting performances with different thresholds
measures_list <- rep(list(list()), 3)

for (thresh in thresholds) {
    res_cv = resample(task_train, learner_train, cv5, store_models = TRUE)
    #combined prediction of all individual resampling iterations
    prediction <- res_cv$prediction()
    prediction$set_threshold(thresh)
    #scores are combined as well from all individual resampling iterations
    scores <- prediction$score(measures = c(msr("classif.acc"),msr("classif.sensitivity"),msr("classif.specificity")))
    coefficients <- (unname(scores))
    measures_list <- mapply(append, measures_list, coefficients, SIMPLIFY = FALSE)
}

measures <- data.frame(thresholds,
                       "accuracy" = unlist(measures_list[[1]]), 
                       "sensitivity" = unlist(measures_list[[2]]),
                       "specificity" = unlist(measures_list[[3]]))

#finding optimal point: intersection
equivalent <- function(x, y, tol = 0.02) abs(x - y) < tol
intersection_indices <- which(equivalent(measures$sensitivity,measures$specificity))
th <- mean(thresholds[intersection_indices]) 

melt_measures <- melt(measures, id.vars="thresholds")
ggplot(melt_measures, aes( x=thresholds, y=value, colour=variable, group=variable )) + 
  geom_line() +
  geom_vline(xintercept = th,linetype = "dotted") +
  geom_label(aes(x = 0.67, y = 0.5, label = as.character(mean(thresholds[intersection_indices]))))

```

Optimal threshold is 0.65.
Since the choice of the threshold depends on the aim of the analysis, we decided to use the level which corresponds to the intersection between accuracy, specificity, and sensitivity, as our aim is to build a predictor which would havee the best behaviour on different data.◊

### Complete model test performance 
```{r}
# define new task for test set
task_test = TaskClassif$new(id = "wines_test",  wwines[-train_indices,], target = "quality", positive = "high")
# train on train task
learner_train$train(task_train)
# predict on test task
pred <- learner_train$predict(task_test)
# set optimal threshold
pred$set_threshold(th)
# performance
cm <- list("confusion" = pred$confusion,
          "accuracy" = pred$score(measures = msr("classif.acc")),
          "sensitivity"=pred$score(measures = msr("classif.sensitivity")),
          "specificity"=pred$score(measures = msr("classif.specificity")))
cm

```

## Model selection
◊ get a better viz
### vif
```{r}
a <- vif(lr_fit)
#b <- data.frame(a,colnames(wwines)[-12])  %>% mutate(sqrt = sqrt(a)) %>% filter(sqrt > 2)
sqrt(vif(lr_fit))>2 # residual.sugar, density, alcohol
```

Variance inflation factor measures how much the behavior (variance) of an independent variable is influenced, or inflated, by its interaction/correlation with the other independent variables.

Residual sugar, density and alcohol are the most influenced by their interactions with other independent variables.


### Forward Stepwise method
```{r}
library(leaps)
regfit.fwd=regsubsets(quality~.,data=wwines,method="forward", nvmax=13)
summary.fwd <- summary(regfit.fwd)

plot(summary.fwd$bic,xlab="Number of Variables",ylab="bic")
points(which.min(summary.fwd$bic),summary.fwd$bic[which.min(summary.fwd$bic)],pch=20,col="red")
```
Forward stepwise steps:
1. inclusion of alcohol
2. inclusion of volatile.acidity
3. inclusion of residual.sugar
4. inclusion of sulphates
5. inclusion of fixed.acidity
6. inclusion of free.sulfur.dioxide
7. inclusion of total.sulfur.dioxide
8. inclusion of pH
9. inclusion of chlorides 
10. inclusion of citric.acid

```{r}
plot(regfit.fwd,scale="bic")
grid(nx=11,ny=10,col="red",lty = "solid")
abline(h=10, col="yellow", lwd = 10)
text(10.5,9, "Optimal model", col="yellow",cex = 0.8)
```


## Restricted model: only 6 variables

Only including: fixed.acidity, volatile.acidity, residual.sugar, free.sulfur.dioxide, sulphates, alcohol.
```{r}
wwines.res <- wwines[,c(1,2,4,6,9,10,11)]
lr_fit_res <- glm(quality ~., data =  wwines.res[train_indices,],
          family=binomial(link='logit'))

# coefficients
summary(lr_fit_res)

# odds ratios
exp(cbind(OR = coef(lr_fit_res), confint(lr_fit_res)))
```
Here we find these variable which are significant at 99% confidence level:
- Intercept 99.98%: this value corresponds to the decrease in the odds of having a low quality wine when all the explanatory variables are set at 0.
- fixed.acidity: a unitary increase in volatile acidity will lead to a 18.07% decrease in the odds of having a low quality wine.
- volatile.acidity: a unitary increase in volatile acidity will lead to a 99.89% decrease in the odds of having a low quality wine.
- residual.sugar: a unitary increase in volatile acidity will lead to a 7.2% increase in the odds of having a low quality wine.
- free.sulfur.dioxide: a unitary increase in volatile acidity will lead to a 0.92% increase in the odds of having a low quality wine.
- alcohol: a unitary increase in volatile acidity will lead to a 196.73% increase in the odds of having a low quality wine.

We find these variable which are significant at 95% confidence level:
- sulphates: a unitary increase in volatile acidity will lead to a 223.72% increase in the odds of having a low quality wine.

## Test performances of restricted and unrestricted models
```{r, warning=FALSE}
#unrestricted model performance
unrestr_probs <- predict(lr_fit,  wwines[-train_indices,], type="response")
unrestr_preds <- ifelse(unrestr_probs > th,"high","low")
unrestr_cm <- confusionMatrix(factor(unrestr_preds),
                         wwines[-train_indices,]$quality,
                        positive = "high"
                        )
unrestr_performance <- list(unrestr_cm$overall[1], unrestr_cm$byClass[1], unrestr_cm$byClass[2])

#restricted model performance
restr_probs <- predict(lr_fit_res,  wwines.res[-train_indices,], type="response")
restr_preds <- ifelse(restr_probs > th,"high","low")
restr_cm <- confusionMatrix(factor(restr_preds),                         wwines[-train_indices,]$quality,
                        positive = "high"
                        )
restr_performance <- list(restr_cm$overall[1], restr_cm$byClass[1], restr_cm$byClass[2])


data.frame("unrestr_performance" =unlist(unrestr_performance),"restr_performance" = unlist(restr_performance), 
           "improvement" = unlist(restr_performance)-unlist(unrestr_performance))
```
There is a little improvement in the performance of the restricted model.


## Detecting outliers (first)
```{r, warning=FALSE}
#see Cook's distance
influenceIndexPlot(lr_fit, id.n=10)  # 2782, 4481
#using dffits
df_fits<-dffits(lr_fit)
threshold<-(2*(11+1)/sqrt(3429-11-1))  
which(abs(df_fits)>threshold) # 2782, 1956
outliers <- c(1956,2782,4481)
 wwines[train_indices,]["outlier"] <- ifelse(rownames( wwines[train_indices,]) %in% outliers,0,1)
residualPlots(lr_fit, id = TRUE,  col = as.factor( wwines[train_indices,]$outlier))
```
From the first plot we identify as outliers instances number 2782 and 4481 (see Cook's distance plot). These instances are outliers for the independent variables distributions.

2782 and 1956 are outliers for the distribution of the response variable (dffits).

## Detecting outliers using unrestricted model (second)
```{r, warning=FALSE}

#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))  
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <- 
  augment(lr_fit) %>%
  mutate(df = unname(dffits(lr_fit)))%>%
  filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold)

wwines[train_indices,]["outlier"] <- ifelse(rownames(wwines[train_indices,]) %in% outliers$.rownames,0,1)
residualPlots(lr_fit, id = TRUE, col = as.factor( wwines[train_indices,]$outlier), ask = FALSE)
```

## Removing outliers from training set
```{r}
no_outliers_train_indices <- c()
j<-1
for(i in 1:length(train_indices)){
  if (!(train_indices[i] %in% as.numeric(outliers$.rownames))){
    no_outliers_train_indices[j] <- train_indices[i]
    j<-j+1
  }
}
```


## Outliers free model (first)
```{r}
#removing useless columns
wwines[train_indices,]$outlier<- NULL
#fitting on outlier free data
lr_fit_outlierfree <- glm(quality ~., data =  wwines[no_outliers_train_indices,],
                          family=binomial(link='logit'))

# coefficients
summary(lr_fit_outlierfree)

# odds ratios
exp(cbind(OR = coef(lr_fit_outlierfree), confint(lr_fit_outlierfree)))
```

## Outliers free model (second)
```{r}
#removing useless columns
wwines[train_indices,]$outlier<- NULL
#fitting on outlier free data
lr_fit_outlierfree <- glm(quality ~., data =  wwines[no_outliers_train_indices,],
                          family=binomial(link='logit'))

# coefficients
summary(lr_fit_outlierfree)

# odds ratios
exp(cbind(OR = coef(lr_fit_outlierfree), confint(lr_fit_outlierfree)))
```

## With and without outliers

### Estimated coefficients
```{r}
outliers <- data.frame(summary(lr_fit)$coefficient)
no_outliers<- data.frame(summary(lr_fit_outlierfree)$coefficient)

variable<-c("(constant)",colnames(wwines)[-c(1,12)])

data.frame(variable,outliers$Estimate,no_outliers$Estimate, "difference"=outliers$Estimate-no_outliers$Estimate)
```

### Performance on test
```{r}
# outliers free
lr_prob_of <- predict(lr_fit_outlierfree,  wwines[-train_indices,], type="response")
lr_pred_of <- ifelse(lr_prob_of > th,"high","low")
cm_of <- confusionMatrix(as.factor(lr_pred_of),
                         wwines[-train_indices,]$quality,
                        positive = "high"
                        )

out_performance <- list(unrestr_cm$overall[1], unrestr_cm$byClass[1], unrestr_cm$byClass[2])
outfree_performance <- list(cm_of$overall[1], cm_of$byClass[1], cm_of$byClass[2])

data.frame("outliers_performance" = unlist(out_performance),"outliers_free_performance" = unlist(outfree_performance), 
           "improvement" = unlist(outfree_performance)-unlist(out_performance))
```

# Outliers free ROC Curve

```{r, message=FALSE, warning=FALSE}
test_roc = roc( wwines[-train_indices,]$quality ~ lr_prob_of, plot = TRUE, print.auc = TRUE)

```

################################################################################
# BAGGING 
```{r}
n <- seq(nrow( wwines[train_indices,]))
set.seed(1)
S1 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(2)
S2 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(3)
S3 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(4)
S4 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
lr_b <- function(i){
      lr_f <- glm(quality ~ fixed.acidity+volatile.acidity+residual.sugar+free.sulfur.dioxide+sulphates+alcohol, 
                  data =  wwines[train_indices,][i, ],family=binomial(link='logit'))
      lr_prob <- predict(lr_f, wwines[train_indices,][i,], type="response")
      lr_pred <- ifelse(lr_prob > th,"high","low")
      cm <- confusionMatrix(
                as.factor(lr_pred),
                 wwines[train_indices,][i,]$quality,
                positive = "high"
                )
      a <- cm$overall[[1]]
      return(a)
}
aggregate = (lr_b(S1) +lr_b(S2) + lr_b(S3) + lr_b(S4))/4
round(aggregate,4)
```

################################################################################

