---
title: "wine_quality"
author: "LJSSE"
date: "19/5/2021"
output: html_document
---

### Importing packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(reshape2)
library(mlr3learners)
library(pROC)
library(corrplot)
library(gridExtra)
library(GGally)
library(car)
library(broom)
library(ltm)
library(MASS)
```

################################################################################
## DATA

The dataset **white_wines.csv** stores data about physicochemical properties of many wines which come from the north-west region, named Minho, of Portugal.

Each row refers to a wine and each column contains one of the physicochemical properties with respect to wines. Here we list the properties:

- fixed acidity (FA: g(tartaric acid)/dm^3)
- volatile acidity (VA: g(acetic acid)/dm^3)
- citric acid (CA: g/dm^3)
- residual sugar (RS: g/dm^3)
- chlorides (CH: g(sodium chloride)/dm^3)
- free sulfur dioxide (FSD: mg/dm^3)
- total sulfur dioxide (TSD: mg/dm^3)
- density (DE: g/dm^3)
- pH
- sulphates (SU: g(potassium sulphate)/dm^3)
- alcohol (AL: %vol)
- quality (from 0 to 10)

Our aim is to classify white wines according to their quality, labeling them as "low" if their quality score is from 0 to 5, and as "high" if the score is between 6 and 10.


## Loading the dataset

```{r, message=FALSE, warning = FALSE}
wwines <- read.csv("winequality-white.csv", sep=";")
print("White wines")
str(wwines)
```

Now we inspect the variables we have and we transform them if necessary.

## Defining the target: high and low quality

```{r, message=FALSE, warning = FALSE}
wwines$quality <- as.factor(case_when(wwines$quality <= 5 ~ "low",
                                      wwines$quality > 5 ~ "high"))
wwines$quality <- factor(wwines$quality, levels = c("low","high"))
table(wwines$quality)
```


## Data description

### Heatmap
```{r}
#compute on all features (without output variable which is at index 12)
cors <- cor(wwines[-12])
corrplot(cors, type = "upper", 
         tl.col = "black", tl.srt = 45)

```
We have to worry about two correlations: residual.sugar with density and density with alcohol.

### Histograms
```{r}
residual.sugar.plot <- ggplot(wwines, aes(residual.sugar, color = quality))+
  geom_freqpoly(binwidth = 3, size = 1)

alcohol.plot <- ggplot(wwines, aes(alcohol, color = quality))+
  geom_freqpoly(binwidth = 3, size = 1)

density.plot <- ggplot(wwines, aes(density, color = quality))+
  geom_freqpoly(binwidth = 3, size = 1)

grid.arrange(residual.sugar.plot,alcohol.plot,density.plot, ncol=1)

```
We decide to remove density, as this will solve both the correlation issues, and we can see from the histograms below that the distribution of density does not depend on quality, while the shape of the residual.sugar and alcohol curves changes for low and high quality wines.

```{r}
wwines$density <- NULL
```

```{r}
a <- vif(lr_fit)
#b <- data.frame(a,colnames(wwines)[-12])  %>% mutate(sqrt = sqrt(a)) %>% filter(sqrt > 2)
sqrt(vif(lr_fit))>2 # residual.sugar, density, alcohol
```

Variance inflation factor measures how much the behavior (variance) of an independent variable is influenced, or inflated, by its interaction/correlation with the other independent variables.

Checking the VIF after the variable "density" removal we can confirm that no other variable is influenced by the others.

### Correlation with target variable
```{r, warning=FALSE, message=FALSE}
bicorrs <- sapply(wwines[,-11], function(x) round(biserial.cor(x,wwines$quality),2))
data.frame(bicorrs) %>% arrange(abs(bicorrs))
```
Here the correlations are displayed in ascending absolute value, and we can see that the variable showing the highest correlation with wines' quality is alcohol.
The sign is positive, meaning that as alcohol increases the quality of wine also increases.

### Boxplots
```{r, message=FALSE, warning = FALSE}
summary(wwines)
# melt the dataset
wwines.m <- melt(wwines, id.var = "quality")

# wrapped boxplots
ggplot(data = wwines.m, aes(x=variable, y=value)) +
geom_boxplot(aes(fill=quality)) +
facet_wrap( ~ variable, scales="free")
```

These plots allow us to get a first impression about which variables will be significant for the regression.

We can observe the following:
- The features displaying the highest median difference between high and low quality wines are volatile.acidity, total.sulfur.dioxide, pH, alcohol.
- There are some outlying values. We will deal with them in the section below.

## Data distinction: training and test set

```{r}
set.seed(42)
train_indices<- createDataPartition(wwines$quality,p=0.7,list=FALSE)
```
###########################################################################

# VARIABLE SELECTION
## Forward Stepwise method
```{r}
library(leaps)
regfit.fwd=regsubsets(quality~.,data=wwines,method="forward", nvmax=13)
summary.fwd <- summary(regfit.fwd)

plot(summary.fwd$bic,xlab="Number of Variables",ylab="bic")
points(which.min(summary.fwd$bic),summary.fwd$bic[which.min(summary.fwd$bic)],pch=20,col="red")
```
Forward stepwise steps:
1. inclusion of alcohol
2. inclusion of volatile.acidity
3. inclusion of residual.sugar
4. inclusion of sulphates
5. inclusion of fixed.acidity
6. inclusion of free.sulfur.dioxide
7. inclusion of total.sulfur.dioxide
8. inclusion of pH
9. inclusion of chlorides 
10. inclusion of citric.acid

Optimal number of variables: 6.

```{r}
plot(regfit.fwd,scale="bic")
grid(nx=11,ny=10,col="red",lty = "solid")
abline(h=10, col="yellow", lwd = 10)
text(10.5,9, "Optimal model", col="yellow",cex = 0.8)
```

# LOGISTIC REGRESSION

The restricted model has only 6 variables.
Only including: fixed.acidity, volatile.acidity, residual.sugar, free.sulfur.dioxide, sulphates, alcohol.
```{r}
wwines.res <- wwines[,c(1,2,4,6,9,10,11)]
lr_fit_res <- glm(quality ~., data =  wwines.res[train_indices,],
          family=binomial(link='logit'))

# coefficients
summary(lr_fit_res)

# odds ratios
exp(cbind(OR = coef(lr_fit_res), confint(lr_fit_res)))
```
Here we find these variable which are significant at 99% confidence level:
- Intercept 99.98%: this value corresponds to the decrease in the odds of having a high quality wine when all the explanatory variables are set at 0.
- fixed.acidity: a unitary increase in volatile acidity will lead to a 18.07% decrease in the odds of having a high quality wine.
- volatile.acidity: a unitary increase in volatile acidity will lead to a 99.89% decrease in the odds of having a high quality wine.
- residual.sugar: a unitary increase in volatile acidity will lead to a 7.2% increase in the odds of having a high quality wine.
- free.sulfur.dioxide: a unitary increase in volatile acidity will lead to a 0.92% increase in the odds of having a high quality wine.
- alcohol: a unitary increase in volatile acidity will lead to a 196.73% increase in the odds of having a high quality wine.

We find these variable which are significant at 95% confidence level:
- sulphates: a unitary increase in volatile acidity will lead to a 223.72% increase in the odds of having a high quality wine.

### Model test performance 
```{r}
#here we use mlr3 package
#defining our task: classification on wines with quality as response variable and low quality as baseline
task_train = TaskClassif$new(id = "wines",  wwines.res[train_indices,], target = "quality", positive = "high")
#defining the learner which will perform the training procedure on our model
learner = lrn("classif.log_reg", predict_type = "prob")
#defining how we want to perform cross validation (setting number of folds to 5)
cv5 = rsmp("cv", folds = 5)
# define new task for test set
task_test = TaskClassif$new(id = "wines_test",  wwines.res[-train_indices,], target = "quality", positive = "high")
# train on train task
learner$train(task_train)
# predict on test task
base_pred <- learner$predict(task_test)

# performance
cm_base <- list("confusion" = base_pred$confusion,
          "accuracy" = base_pred$score(measures = msr("classif.acc")),
          "sensitivity"=base_pred$score(measures = msr("classif.sensitivity")),
          "specificity"=base_pred$score(measures = msr("classif.specificity")))
cm_base
```

## Detecting outliers using restricted model 
```{r, warning=FALSE}
#cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit_res, which = 4, id.n = 3)
outliers <- 
  augment(lr_fit_res) %>%
  filter(.cooksd > 4/nrow(wwines.res[train_indices,]))

wwines.res[train_indices,]["outlier"] <- ifelse(rownames(wwines.res[train_indices,]) %in% outliers$.rownames,0,1)
residualPlots(lr_fit_res, id = TRUE, col = as.factor(wwines.res[train_indices,]$outlier), ask = FALSE)
```

## Removing outliers from training set
```{r}
no_outliers_train_indices <- c()
j<-1
for(i in 1:length(train_indices)){
  if (!(train_indices[i] %in% as.numeric(outliers$.rownames))){
    no_outliers_train_indices[j] <- train_indices[i]
    j<-j+1
  }
}
```


## Outliers free model
```{r}
#removing useless columns
wwines.res[train_indices,]$outlier<- NULL
#fitting on outlier free data
lr_fit_outlierfree <- glm(quality ~., data =  wwines.res[no_outliers_train_indices,],                          family=binomial(link='logit'))

# coefficients
summary(lr_fit_outlierfree)

# odds ratios
exp(cbind(OR = coef(lr_fit_outlierfree), confint(lr_fit_outlierfree)))
```

## Performance
```{r}
task_train = TaskClassif$new(id = "wines_outlierfree",  wwines.res[no_outliers_train_indices,], target = "quality", positive = "high")

learner = lrn("classif.log_reg", predict_type = "prob")

cv5 = rsmp("cv", folds = 5)

task_test = TaskClassif$new(id = "wines_outlierfree_test",  wwines.res[-no_outliers_train_indices,], target = "quality", positive = "high")

learner$train(task_train)

outlierfree_pred <- learner$predict(task_test)
# set optimal threshold
#pred$set_threshold(th)
cm_outlierfree <- list("confusion" = outlierfree_pred$confusion,
          "accuracy" = outlierfree_pred$score(measures = msr("classif.acc")),
          "sensitivity"=outlierfree_pred$score(measures = msr("classif.sensitivity")),
          "specificity"=outlierfree_pred$score(measures = msr("classif.specificity")))

cm_outlierfree
```

## Performance comparison

```{r}
data.frame("outlierfree_performance" = unlist(cm_outlierfree[-1]),"base_performance" = unlist(cm_base[-1]), 
           "improvement" = unlist(cm_outlierfree[-1])-unlist(cm_base[-1]))
```

### Estimated coefficients
```{r}
base <- data.frame(summary(lr_fit_res)$coefficient)
no_outliers<- data.frame(summary(lr_fit_outlierfree)$coefficient)

variable<-c("(constant)",colnames(wwines.res)[-c(1,12)])

data.frame(variable,base$Estimate,no_outliers$Estimate, "difference"=base$Estimate-no_outliers$Estimate)
```

# Outliers free ROC Curve --> WHERE TO PUT THIS?

```{r, message=FALSE, warning=FALSE}
test_roc = roc( wwines.res[-no_outliers_train_indices,]$quality ~ lr_fit_outlierfree, plot = TRUE, print.auc = TRUE)

```
# OPTIMAL THRESHOLD

Finding the optimal threshold for discriminating high quality wines from low quality wines.

```{r}
#we want to tweak the threshold of our classification: we analyze values from 0.3 to 0.6 with step 0.01
thresholds <- seq(0.5,0.8,0.01)

#collecting performances with different thresholds
measures_list <- rep(list(list()), 3)

for (thresh in thresholds) {
    res_cv = resample(task_train, learner, cv5, store_models = TRUE)
    #combined prediction of all individual resampling iterations
    prediction <- res_cv$prediction()
    prediction$set_threshold(thresh)
    #scores are combined as well from all individual resampling iterations
    scores <- prediction$score(measures = c(msr("classif.acc"),msr("classif.sensitivity"),msr("classif.specificity")))
    coefficients <- (unname(scores))
    measures_list <- mapply(append, measures_list, coefficients, SIMPLIFY = FALSE)
}

measures <- data.frame(thresholds,
                       "accuracy" = unlist(measures_list[[1]]), 
                       "sensitivity" = unlist(measures_list[[2]]),
                       "specificity" = unlist(measures_list[[3]]))

#finding optimal point: intersection
equivalent <- function(x, y, tol = 0.02) abs(x - y) < tol
intersection_indices <- which(equivalent(measures$sensitivity,measures$specificity))
th <- mean(thresholds[intersection_indices]) 

melt_measures <- melt(measures, id.vars="thresholds")
ggplot(melt_measures, aes( x=thresholds, y=value, colour=variable, group=variable )) + 
  geom_line() +
  geom_vline(xintercept = th,linetype = "dotted") +
  geom_label(aes(x = 0.67, y = 0.5, label = as.character(mean(thresholds[intersection_indices]))))

```

Optimal threshold is 0.665.
Since the choice of the threshold depends on the aim of the analysis, we decided to use the level which corresponds to the intersection between accuracy, specificity, and sensitivity, as our aim is to build a predictor which would have the best behaviour on different data.

## Performance
```{r}
task_train = TaskClassif$new(id = "wines_outlierfree",  wwines.res[no_outliers_train_indices,], target = "quality", positive = "high")

learner = lrn("classif.log_reg", predict_type = "prob")

cv5 = rsmp("cv", folds = 5)

task_test = TaskClassif$new(id = "wines_outlierfree_test",  wwines.res[-no_outliers_train_indices,], target = "quality", positive = "high")

learner$train(task_train)

opt_th_pred <- learner$predict(task_test)
# set optimal threshold
opt_th_pred$set_threshold(th)

cm_opt_th<- list("confusion" = opt_th_pred$confusion,
          "accuracy" = opt_th_pred$score(measures = msr("classif.acc")),
          "sensitivity"=opt_th_pred$score(measures = msr("classif.sensitivity")),
          "specificity"=opt_th_pred$score(measures = msr("classif.specificity")))

cm_opt_th
```

## Performance comparison

```{r}
data.frame("optimal_threshold_preformance" = unlist(cm_opt_th[-1]),
  "outlierfree_performance" = unlist(cm_outlierfree[-1]),"base_performance" = unlist(cm_base[-1]), 
           "improvement_from_last" = unlist(cm_opt_th[-1])-unlist(cm_outlierfree[-1]))
```

################################################################################
# BAGGING 
```{r}
n <- seq(nrow( wwines[train_indices,]))
set.seed(1)
S1 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(2)
S2 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(3)
S3 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(4)
S4 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
lr_b <- function(i){
      lr_f <- glm(quality ~ fixed.acidity+volatile.acidity+residual.sugar+free.sulfur.dioxide+sulphates+alcohol, 
                  data =  wwines[train_indices,][i, ],family=binomial(link='logit'))
      lr_prob <- predict(lr_f, wwines[train_indices,][i,], type="response")
      lr_pred <- ifelse(lr_prob > th,"high","low")
      cm <- confusionMatrix(
                as.factor(lr_pred),
                 wwines[train_indices,][i,]$quality,
                positive = "high"
                )
      a <- cm$overall[[1]]
      return(a)
}
aggregate = (lr_b(S1) +lr_b(S2) + lr_b(S3) + lr_b(S4))/4
round(aggregate,4)
```

################################################################################

